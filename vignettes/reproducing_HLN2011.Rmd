---
title: "Reproducing Hansen, Lunde and Nason (2011)"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Reproducing}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
bibliography: lit.bib
---

# Intro

This text will provide examples of the main functions of this package. These functions estimate model confidence sets (MCS) based on a set of competing model specifications that are provided by the user. The functions are therefore useful if you want to account for the uncertainty surround you choice of model. Hopefully, by the end of this text you will have a better idea of what these confidence sets are and how to use them. The functionality has already been implemented elsewhere in R, so you might wonder why I follow the fruitless task of creating this package and this vignette. The answer is simple and twofold. First, to practise. I want to finish my first, half-baked attempt at creating an R package. Second, I will compare the accuracy and efficiency of the different implementations available in R.

# A First Glance

Let's get going. As a first example, we will look at 

CONTINUE: create ar, time trend, intercept, RW? arch, dummies? and compete
```{r}
# ?datasets::EuStockMarkets
data(EuStockMarkets)
colnames(EuStockMarkets)
str(EuStockMarkets)
class(EuStockMarkets)


typeof(EuStockMarkets)

DAX <- EuStockMarkets[, 1]
plot(DAX)
plot(log(DAX))

# change in DAX level
y <- diff(log(DAX))
plot(y)

# I need rolling forecasts ... 
# -> re-use helper functions from elsewhere...

# AR
ar(y, order.max = 5, aic = FALSE)

# RW = no-change = 0 / intercept?
y_pred = 0

# drift?
lm(y ~ + 1)

# two unit roots? several or fractional unit roots?
lmy(y ~ lag(y)) # how to impose? NOT ACTUALLY LAGGED...

# Time-trend -> will be intercept of change?
lm(DAX ~ seq_along(DAX))
lm(y ~ 1)

# Week-of-day Dummies
# need to match with date...
# 2.01.1991 - 31.12.1998 ? 
# which are business dates?
ALL TO COMPLICATED; keep it simple. three models at most.

# GARCH
# check out last assignment again...

```







what? application in HLN 2011. which page? which table? 
  
* SW inflation forecasts 

Out-of-sample version
different t-stats
timing?

```{r}
library(modelconf)
data(SW_infl4cast)
data <- as.matrix(SW_infl4cast)
loss <- (data[, -1] - data[, 1])^2 # compute squared errors

# Estimate MCS same way that Hansen, Lunde, Nason (2011) did.
# Note: "t.min" should not be used in practice.

my_MCS <- estMCS(loss, test = "t.min", B = 25000, l = 12)

my_MCS
```

Results are equivalent (up to rounding and simulation error) in column 1 of page 485 in @HansenLundeNason2011Model.

-->>>>>>>> What is shown in table? Contents??


```{r}
my_MCS[my_MCS[, "MCS p-val"] > 0.1, ] # actual, estimated MCS at alpha = 0.1
```


* Taylor Rule regressions

In-sample version
KLIC, AIC, ...
timing?

## Alternatives

There are two other implementations of the MCS procedure available in R. One is provided by the [MCS package](https://cran.r-project.org/web/packages/MCS/index.html), the other by the [rugarch package](https://cran.r-project.org/web/packages/rugarch/index.html). Both of them focus on the out-of-sample variant and leave the in-sample variant aside.

PLUS: https://insightr.wordpress.com/2017/09/03/combining-and-comparing-models-using-model-confidence-set/
quick and dirty by Gabriel Vasconcelos

Here, I will compare the accuracy and the performance of the three implementations. 

As example data; I will use the inflation forecast exercise by @StockWatson1999Forecasting which was also studied as a test case by @HansenLundeNason2011Model. Results can therefore be compared with results therein. At least to a certain degree, because the orignial work by @HansenLundeNason2011Model contained a coding error. Due to a wrong sign, the test statistic used was t_min instead of t_max. While still consistent, the t_min statistic violates one of the assumptions made in HLN (which assumption specifically? see [Corrigendum](https://9b31dea8-a-62cb3a1a-s-sites.googlegroups.com/site/peterreinhardhansen/research-papers/themodelconfidenceset/CorrigendumAll.pdf?attachauth=ANoY7cpS8f8NinjW-h4-_dAYqEhTW9YPSqselKXM0iEWr9qPuZXyRGTZtfpZ0n07LdnOQaca3C_QFvf5AxNBLv5fgNO07QJgo68B1hkrMUFqFEk4BcpX4GJh1l2vszEw8qfpgBFfZg01PznNHSQJ6J2qOpY-dD3Kr1-9a_jDN9DXQxKXh_zYk4HYFa7qxF115ALLUTRy23XeJFVUUIlN9b4ugwj1beEx5p8vbGEs4PeDF1NHcYvItG4um2gPYbHO42exCsUKi-kTQFhjL-arUdxSLRTkc7yeRA%3D%3D&attredirects=0])

When comparing to the original work, this error must be taken into account. Luckily, the *modelconf* package can produce results using both the correct and the inadvertantly used test statistic.



(caveat: t_max vs. t_min: coding error <- comment)


READ: https://pdfs.semanticscholar.org/d252/94807fa7b8302610aa5fcb8a4ddade162562.pdf

Cite: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2692118
Cite: HLN econometrica paper






* Conclusion

# References
